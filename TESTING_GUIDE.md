# Testing Guide - Multi-Agent Workflow Studio

**Phase 1 Complete** - Ready for Testing
**Branch:** `phase-1/foundation`
**Date:** January 16, 2026

---

## Prerequisites

### 1. Get API Keys

You'll need at least one API key to test live execution:

- **OpenAI** (Recommended for first test)
  - Go to: https://platform.openai.com/api-keys
  - Click "Create new secret key"
  - Copy the key (starts with `sk-`)
  - Cost: ~$0.001 per test (using gpt-4o-mini)

- **Anthropic** (Optional)
  - Go to: https://console.anthropic.com/
  - Click "Get API Keys"
  - Create a new key
  - Cost: ~$0.003 per test (using claude-haiku-4)

- **Google AI** (Optional)
  - Go to: https://aistudio.google.com/
  - Get API key from settings
  - Cost: Free tier available

- **Ollama** (Optional - Local)
  - Install from: https://ollama.ai
  - Run: `ollama pull llama3.2`
  - No API key needed, runs locally

### 2. Start the Development Server

```bash
# Make sure you're on the correct branch
git checkout phase-1/foundation

# Install dependencies (if not already done)
pnpm install

# Start dev server
pnpm dev
```

Open http://localhost:3000 in your browser.

---

## Test Suite

### Test 1: Settings & API Key Configuration âš™ï¸

**What it tests:** Settings panel, API key storage, validation

**Steps:**
1. Click the **Settings** icon (âš™ï¸) in the top toolbar
2. Settings modal should open
3. Find the **OpenAI** section
4. Click in the API key input field
5. Paste your OpenAI API key (starts with `sk-`)
6. Click the **Test** button next to the input
7. Wait for validation (~2-3 seconds)
8. Status should change to **âœ“ Connected**
9. Click **Save** button at bottom
10. Close modal by clicking X or outside

**Expected Results:**
- âœ… Settings modal opens smoothly
- âœ… API key is masked (shows â€¢â€¢â€¢â€¢ instead of actual key)
- âœ… Test button shows loading spinner during validation
- âœ… Status updates to "Connected" with green checkmark
- âœ… Save button stores the key
- âœ… Modal closes properly

**Troubleshooting:**
- If validation fails: Check API key is correct and has credits
- If "Invalid API key" shows: Key may be incorrect or expired
- If timeout: Check internet connection

---

### Test 2: Basic Agent Node (Mock Mode) ğŸ¤–

**What it tests:** Agent nodes, properties panel, mock execution

**Steps:**
1. From the **Palette** (left sidebar), drag **Agent** onto the canvas
2. Click the agent node to select it
3. Properties panel opens on right
4. In the **Prompt** field, type: `"Write a haiku about coding"`
5. Verify **Mode** is set to **Mock** (default)
6. From palette, drag **Result** node onto canvas
7. Connect Agent â†’ Result:
   - Hover over Agent node's **top edge** (source handle appears)
   - Drag from top of Agent to **bottom edge** of Result
   - Arrow should appear connecting them
8. Click the **Run** button (â–¶) in toolbar
9. Watch the console (bottom panel)

**Expected Results:**
- âœ… Agent node appears on canvas
- âœ… Properties panel shows agent settings
- âœ… Can type in prompt field
- âœ… Connection arrow appears between nodes
- âœ… Console shows: `ğŸ¤– Agent 1 (mock) ... [random string]`
- âœ… Execution completes with: `âœ… Done.`
- âœ… No errors in console

**Troubleshooting:**
- If can't drag: Make sure you're dragging from the node item, not clicking
- If can't connect: Drag from top handle (source) to bottom handle (target)
- If nothing happens on Run: Check nodes are connected

---

### Test 3: Live Agent Execution with Streaming ğŸš€

**What it tests:** Real LLM API calls, streaming, cost tracking

**Steps:**
1. Clear canvas: Click **Clear** button in toolbar
2. Drag new **Agent** node onto canvas
3. Select the agent node
4. In properties panel:
   - **Name**: `"Poet"`
   - **Model**: Select `openai/gpt-4o-mini` from dropdown
   - **Mode**: Click **Live** radio button
   - **Streaming**: Check the checkbox
   - **Prompt**: `"Write a haiku about AI and creativity"`
5. Drag **Result** node onto canvas
6. Connect: Poet â†’ Result
7. Click **Run** â–¶
8. Watch the console closely

**Expected Results:**
- âœ… Node border turns **blue** and pulses (executing state)
- âœ… Console shows: `ğŸ¤– Poet: [streaming text appears character by character]`
- âœ… Text streams in real-time with cursor: `â–Œ`
- âœ… When complete:
  - Full haiku visible
  - Cost displayed: `ğŸ’° Cost: $0.0003 | Tokens: 45` (approximate)
  - Node border turns **green** (completed)
- âœ… Console auto-scrolls to show latest output
- âœ… Total execution time: 2-5 seconds

**Troubleshooting:**
- If "Invalid OpenAI API key": Go back to Settings, re-enter key
- If "Rate limit exceeded": Wait 60 seconds and try again
- If no streaming: Verify streaming checkbox is checked
- If very slow: Network latency, normal for first request

---

### Test 4: Non-Streaming Execution ğŸ“

**What it tests:** Non-streaming mode, different models

**Steps:**
1. Select the Poet agent node from Test 3
2. In properties panel:
   - **Streaming**: **Uncheck** the checkbox
   - **Model**: Change to `openai/gpt-4o` (more expensive model)
   - **Temperature**: Drag slider to `0.9` (more creative)
3. Click **Run** â–¶
4. Observe different behavior

**Expected Results:**
- âœ… No streaming cursor appears
- âœ… Console shows "waiting..." message
- âœ… After 2-3 seconds, full response appears at once
- âœ… Cost is higher: `ğŸ’° Cost: $0.002-0.004` (gpt-4o is more expensive)
- âœ… Response may be more creative (temperature 0.9)

**Troubleshooting:**
- Higher cost is expected for gpt-4o vs gpt-4o-mini
- If timeout: Model may be busy, retry

---

### Test 5: Document Upload (Text File) ğŸ“„

**What it tests:** Document node, file upload, text extraction

**Steps:**
1. Create a test file on your computer:
   - Create file named `test.txt`
   - Content: `"This is a test document. It contains multiple sentences. We will use this to test document processing."`
2. Clear canvas
3. Drag **Document** node onto canvas
4. Select document node
5. In properties panel:
   - Click **Choose File** button
   - Select your `test.txt` file
   - Wait for upload
6. Observe the node and properties

**Expected Results:**
- âœ… Node shows filename: `test.txt`
- âœ… Node shows size: `~0.1 KB`
- âœ… Properties show:
  - File name
  - File type: TXT
  - Size in KB
  - Character count
  - Content preview (scrollable)
- âœ… Preview shows: `"This is a test document..."`

**Troubleshooting:**
- If upload fails: Check file size (should be < 10MB)
- If no preview: Refresh page and try again

---

### Test 6: Document Upload (PDF) ğŸ“‘

**What it tests:** PDF text extraction with pdf-parse

**Steps:**
1. Find or create a simple PDF file
   - Can use: Any PDF with text content (not just images)
   - Or create one by printing a web page to PDF
2. Clear canvas (or use new document node)
3. Drag **Document** node onto canvas
4. Select it
5. Upload your PDF file
6. Wait 2-5 seconds for extraction

**Expected Results:**
- âœ… Node shows PDF filename
- âœ… Node shows size
- âœ… Node shows character count (may be large)
- âœ… Properties show extracted text in preview
- âœ… Text is readable (not garbled)
- âœ… Multi-page PDFs: all pages extracted

**Troubleshooting:**
- If extraction fails: Try a different PDF (some PDFs have image-only text)
- If takes long time: Large PDFs (>100 pages) may take 10-30 seconds
- If garbled text: PDF may have special encoding

---

### Test 7: Document â†’ Agent Workflow ğŸ”—

**What it tests:** Document content flowing to agents, context injection

**Steps:**
1. Use the document node from Test 5 or 6 (with uploaded file)
2. Drag **Agent** node onto canvas
3. Connect: Document â†’ Agent (document's top to agent's bottom)
4. Select agent node, configure:
   - **Model**: `openai/gpt-4o-mini`
   - **Mode**: Live
   - **Prompt**: `"Summarize the above document in one sentence."`
5. Drag **Result** node
6. Connect: Agent â†’ Result
7. Click **Run** â–¶

**Expected Results:**
- âœ… Console shows:
  - `ğŸ“„ Document: test.txt (XXX chars)`
  - `ğŸ¤– Agent: [waiting...]`
  - `ğŸ¤– Agent: [summary of your document content]`
  - `ğŸ’° Cost: $0.00XX | Tokens: XX`
  - `ğŸ“¦ Final: [the summary]`
- âœ… Summary is relevant to document content
- âœ… Node borders: Blue (executing) â†’ Green (completed)
- âœ… Execution completes successfully

**Troubleshooting:**
- If summary is generic: Document content may not be passing - check connection
- If "Context too long": Document is very large, cost may be high
- If agent ignores document: Verify connection exists (arrow visible)

---

### Test 8: Document Chunking ğŸ“š

**What it tests:** Chunker node, fixed and semantic chunking

**Steps:**
1. Use existing document node (from Test 7) or upload new file
2. Drag **Chunker** node onto canvas
3. Connect: Document â†’ Chunker
4. Select chunker node, configure:
   - **Strategy**: Fixed
   - **Chunk Size**: 100
   - **Overlap**: 20
5. Drag **Result** node
6. Connect: Chunker â†’ Result
7. Click **Run** â–¶

**Expected Results:**
- âœ… Console shows: `ğŸ“‘ Chunker: Created X chunks`
- âœ… Result shows chunks separated by `---CHUNK---`
- âœ… Each chunk is approximately 100 characters
- âœ… Chunks overlap by ~20 characters
- âœ… Chunker node shows: `"X chunks"` on canvas

**Steps for Semantic:**
1. Select chunker node
2. Change **Strategy** to **Semantic**
3. **Chunk Size**: 200
4. Click **Run** â–¶

**Expected Results:**
- âœ… Chunks split at sentence boundaries
- âœ… No sentences cut in middle
- âœ… Chunks are closer to 200 chars (but may vary)

---

### Test 9: Complex RAG Workflow ğŸ§ 

**What it tests:** Multi-node workflow, document chunking + LLM

**Steps:**
1. Clear canvas
2. Build workflow:
   ```
   Document â†’ Chunker â†’ Agent â†’ Result
   ```
3. Configure:
   - **Document**: Upload a longer text file (500+ words)
   - **Chunker**:
     - Strategy: Semantic
     - Chunk Size: 300
     - Overlap: 50
   - **Agent**:
     - Model: `openai/gpt-4o-mini`
     - Mode: Live
     - Streaming: On
     - Prompt: `"Based on the chunks above, what are the main topics discussed?"`
4. Click **Run** â–¶
5. Watch full execution flow

**Expected Results:**
- âœ… Nodes execute in order (left to right)
- âœ… Each node's border:
  - Gray â†’ Blue (executing) â†’ Green (completed)
- âœ… Console shows:
  1. `ğŸ“„ Document: [filename]`
  2. `ğŸ“‘ Chunker: Created X chunks`
  3. `ğŸ¤– Agent: [streaming analysis...]`
  4. `ğŸ’° Cost: $0.00XX`
  5. `ğŸ“¦ Final: [analysis]`
- âœ… Agent's response mentions topics from your document
- âœ… Total time: 3-10 seconds depending on document size

---

### Test 10: Multiple Providers ğŸŒ

**What it tests:** Switching between providers, cost comparison

**Steps:**
1. If you have multiple API keys, configure them in Settings:
   - OpenAI
   - Anthropic (optional)
   - Google AI (optional)
2. Clear canvas
3. Create 3 agent nodes side by side
4. Configure each with same prompt but different models:
   - **Agent 1**:
     - Model: `openai/gpt-4o-mini`
     - Prompt: `"What is the meaning of life?"`
   - **Agent 2**:
     - Model: `anthropic/claude-haiku-4`
     - Prompt: `"What is the meaning of life?"`
   - **Agent 3**:
     - Model: `google/gemini-1.5-flash`
     - Prompt: `"What is the meaning of life?"`
5. Set all to Live mode
6. Create 3 Result nodes, connect each agent to its result
7. Click **Run** â–¶

**Expected Results:**
- âœ… All three agents execute (may be sequential due to topological sort)
- âœ… Console shows different provider responses
- âœ… Cost varies by provider:
  - OpenAI gpt-4o-mini: ~$0.0003
  - Anthropic claude-haiku-4: ~$0.0005
  - Google gemini-flash: ~$0.0001 (cheapest)
- âœ… Responses have different styles/content
- âœ… All complete successfully

**Troubleshooting:**
- If one provider fails: Check that specific API key
- Sequential execution is expected (workflow runs in topological order)

---

### Test 11: Streaming Auto-Scroll ğŸ“œ

**What it tests:** Console auto-scroll behavior

**Steps:**
1. Create agent with very long output:
   - Model: `openai/gpt-4o`
   - Streaming: On
   - Prompt: `"Write a 500-word essay about the future of AI"`
2. Click **Run** â–¶
3. As text streams:
   - Observe console scrolling automatically
   - Manually scroll UP in console (while still streaming)
   - Observe auto-scroll stops
   - Scroll back to BOTTOM
   - Observe auto-scroll resumes

**Expected Results:**
- âœ… Console auto-scrolls during streaming
- âœ… Scrolling up disables auto-scroll
- âœ… Scrolling to bottom re-enables auto-scroll
- âœ… Never lose sight of streaming text
- âœ… Long output (500 words) renders completely

---

### Test 12: Error Handling - Invalid API Key âŒ

**What it tests:** Error states, error messages

**Steps:**
1. Open Settings
2. Change OpenAI API key to invalid value: `sk-invalid123`
3. Save and close
4. Create agent node:
   - Model: `openai/gpt-4o-mini`
   - Mode: Live
   - Prompt: `"Test"`
5. Connect to Result
6. Click **Run** â–¶

**Expected Results:**
- âœ… Node border turns **red** (error state)
- âœ… Console shows: `âŒ [node-id]: Invalid OpenAI API key. Please check your API key and try again.`
- âœ… Execution stops (doesn't continue to result)
- âœ… Error message is clear and actionable

**Troubleshooting:**
- Remember to fix your API key in Settings afterward!

---

### Test 13: Error Handling - Network Error ğŸ”Œ

**What it tests:** Network error handling

**Steps:**
1. Disconnect from internet (WiFi off) OR use invalid model
2. Create agent node:
   - Model: `openai/gpt-4o-mini`
   - Mode: Live
3. Click **Run** â–¶

**Expected Results:**
- âœ… Red error border on node
- âœ… Console shows network error message
- âœ… Execution stops gracefully

**Troubleshooting:**
- Reconnect to internet when done
- If using invalid model, change back to valid one

---

### Test 14: Visual States - Execution Progress ğŸ¨

**What it tests:** Node execution state visualization

**Steps:**
1. Create workflow: `Prompt â†’ Agent (Live, Streaming) â†’ Result`
2. Configure agent with longer response:
   - Prompt: `"Count from 1 to 20 with explanations"`
3. Click **Run** â–¶
4. Watch the nodes carefully

**Expected Results:**
- âœ… Before execution: All nodes have gray borders
- âœ… During execution:
  - Currently executing node: **Blue animated pulsing border**
  - Completed nodes: **Green solid border**
  - Waiting nodes: Gray border
- âœ… After execution: All nodes green
- âœ… Pulse animation is smooth and visible

---

### Test 15: Multiple Documents â†’ One Agent ğŸ“šâ¡ï¸ğŸ¤–

**What it tests:** Multiple inputs to one node, context concatenation

**Steps:**
1. Clear canvas
2. Create two document nodes side by side
3. Upload different files to each:
   - Document 1: `file1.txt` with content: `"The sky is blue."`
   - Document 2: `file2.txt` with content: `"The grass is green."`
4. Create one Agent node
5. Connect **both** documents to the agent:
   - Document 1 â†’ Agent
   - Document 2 â†’ Agent
6. Configure agent:
   - Model: `openai/gpt-4o-mini`
   - Mode: Live
   - Prompt: `"List all the colors mentioned in the documents."`
7. Connect Agent â†’ Result
8. Click **Run** â–¶

**Expected Results:**
- âœ… Both documents execute first
- âœ… Agent receives both documents' content
- âœ… Agent response mentions: "blue" and "green"
- âœ… Documents are separated with `---` in context
- âœ… Execution succeeds

---

### Test 16: Temperature Settings ğŸŒ¡ï¸

**What it tests:** Temperature parameter effects

**Steps:**
1. Create agent:
   - Model: `openai/gpt-4o-mini`
   - Mode: Live
   - Prompt: `"Write a creative opening line for a story."`
2. Run 3 times with different temperatures:
   - **Temperature 0.0**: Click Run, note output
   - **Temperature 1.0**: Click Run, note output
   - **Temperature 2.0**: Click Run, note output

**Expected Results:**
- âœ… Temperature 0.0: Most deterministic, factual, similar on each run
- âœ… Temperature 1.0: Balanced creativity
- âœ… Temperature 2.0: Most creative, varied, potentially less coherent
- âœ… Outputs differ noticeably

---

### Test 17: Max Tokens Limit âœ‚ï¸

**What it tests:** Max tokens parameter

**Steps:**
1. Create agent:
   - Model: `openai/gpt-4o-mini`
   - Mode: Live
   - Streaming: On
   - Prompt: `"Write a 1000-word essay about space exploration."`
   - **Max Tokens**: `50` (very low)
2. Click **Run** â–¶

**Expected Results:**
- âœ… Response cuts off mid-sentence after ~50 tokens (~35-40 words)
- âœ… Cost is lower than if no max tokens
- âœ… Token count shown: ~50-60 tokens (includes input)
- âœ… Streaming stops when limit reached

**Test with higher limit:**
1. Change **Max Tokens** to `500`
2. Run again

**Expected Results:**
- âœ… Much longer response (300-400 words)
- âœ… Higher cost
- âœ… Token count: ~500-600

---

### Test 18: Execution Controls - Pause and Resume â¸ï¸â–¶ï¸

**What it tests:** Pause/resume functionality during workflow execution

**Steps:**
1. Clear canvas
2. Create a workflow with 4 agent nodes in sequence:
   ```
   Agent 1 â†’ Agent 2 â†’ Agent 3 â†’ Agent 4 â†’ Result
   ```
3. Configure all agents:
   - Model: `openai/gpt-4o-mini`
   - Mode: Live
   - Streaming: On
   - Prompts: `"Count to 10 slowly"` (or similar delay-inducing prompts)
4. Click **Run** â–¶
5. Watch first agent execute (blue pulsing border)
6. As soon as first agent completes (turns green), click **Pause** â¸ï¸ button
7. Observe execution state
8. Wait 3-5 seconds
9. Click **Resume** â–¶ï¸ button
10. Watch execution continue

**Expected Results:**
- âœ… Run button appears when workflow is idle
- âœ… After clicking Run:
  - Run button disappears
  - **Pause** and **Cancel** buttons appear
- âœ… After clicking Pause:
  - Current node completes execution (doesn't cut off mid-node)
  - Console shows: `â¸ï¸ Execution paused`
  - Pause button disappears
  - **Resume** and **Cancel** buttons appear
  - Node borders remain in their current state (green for completed, gray for not started)
- âœ… After clicking Resume:
  - Console shows: `â–¶ï¸ Execution resumed`
  - Resume button disappears
  - **Pause** and **Cancel** buttons reappear
  - Next node begins executing (blue pulsing border)
  - Execution continues through remaining nodes
- âœ… All nodes eventually complete (all green borders)

**Troubleshooting:**
- If pause happens mid-node: This is expected - pause waits for current node to finish
- If execution doesn't resume: Check console for errors, try clicking Resume again

---

### Test 19: Execution Controls - Cancel âŒ

**What it tests:** Cancel/abort functionality during workflow execution

**Steps:**
1. Use the same 4-agent workflow from Test 18
2. Click **Run** â–¶
3. Watch first agent start executing (blue border)
4. Click **Cancel** ğŸ›‘ button (appears next to Pause during execution)
5. Observe what happens

**Expected Results:**
- âœ… Console shows: `ğŸ›‘ Execution cancelled`
- âœ… Execution stops immediately (doesn't continue to next node)
- âœ… All node borders reset to gray (idle state)
- âœ… Cancel and Pause buttons disappear
- âœ… Run button reappears
- âœ… Can click Run again to start fresh execution

**Test Cancel While Paused:**
1. Click **Run** â–¶
2. After first node completes, click **Pause** â¸ï¸
3. While paused, click **Cancel** ğŸ›‘

**Expected Results:**
- âœ… Execution cancelled from paused state
- âœ… All nodes reset to gray
- âœ… Console shows cancellation message
- âœ… Run button reappears

**Troubleshooting:**
- Cancellation is irreversible - you'll need to run from start again
- If nodes don't reset: Refresh page and try again

---

### Test 20: Error Recovery - Retry â™»ï¸

**What it tests:** Error dialog and retry functionality

**Steps:**
1. Open Settings
2. Set OpenAI API key to invalid: `sk-invalid-test-key-12345`
3. Click Save and close
4. Clear canvas
5. Create simple workflow:
   ```
   Agent 1 â†’ Agent 2 â†’ Result
   ```
6. Configure Agent 1:
   - Model: `openai/gpt-4o-mini`
   - Mode: Live
   - Prompt: `"Say hello"`
7. Configure Agent 2:
   - Model: `openai/gpt-4o-mini`
   - Mode: Live
   - Prompt: `"Say goodbye"`
8. Click **Run** â–¶
9. Wait for error dialog to appear
10. Observe the error dialog content
11. Keep dialog open, go to Settings
12. Fix API key (enter valid key)
13. Save and close Settings
14. In error dialog, click **Retry** button

**Expected Results:**
- âœ… Error dialog appears showing:
  - âŒ Icon and "Execution Error" title
  - Node name: "Agent 1"
  - Error message: "Invalid OpenAI API key..."
  - Three buttons: **Retry**, **Skip**, **Abort**
- âœ… Node 1 has red border (error state)
- âœ… Console shows error message
- âœ… After fixing API key and clicking Retry:
  - Dialog closes
  - Node 1 resets to idle (gray border)
  - Node 1 re-executes with valid API key
  - Node 1 completes successfully (green border)
  - Agent 2 executes
  - Workflow completes successfully
- âœ… Console shows: `â™»ï¸ Retrying node: Agent 1`

**Troubleshooting:**
- Make sure to actually fix the API key before retrying
- If retry fails again: API key still invalid, check Settings

---

### Test 21: Error Recovery - Skip â­ï¸

**What it tests:** Skip functionality to continue past errors

**Steps:**
1. Use the same workflow from Test 20
2. Ensure Agent 1 has invalid API key (will fail)
3. Ensure Agent 2 has valid API key (should succeed if reached)
4. Click **Run** â–¶
5. When error dialog appears for Agent 1, click **Skip** button

**Expected Results:**
- âœ… Error dialog closes
- âœ… Console shows: `â­ï¸ Skipping node: Agent 1`
- âœ… Node 1 remains with red error border (not reset)
- âœ… Execution continues to Agent 2
- âœ… Agent 2 executes successfully (blue â†’ green)
- âœ… Workflow completes with Agent 1 in error state, Agent 2 completed
- âœ… Result node receives output from Agent 2 only

**Use Case:**
Skip is useful when:
- One node in a workflow is non-critical
- You want to see results from other nodes despite one failure
- Testing workflows with partially broken components

---

### Test 22: Error Recovery - Abort ğŸ›‘

**What it tests:** Abort functionality from error dialog

**Steps:**
1. Use the same workflow from Test 20
2. Ensure Agent 1 has invalid API key
3. Click **Run** â–¶
4. When error dialog appears, click **Abort** button

**Expected Results:**
- âœ… Error dialog closes
- âœ… Console shows: `ğŸ›‘ Execution cancelled`
- âœ… All nodes reset to gray (idle state)
- âœ… Execution stops completely
- âœ… Run button reappears
- âœ… No further nodes execute

**Comparison:**
- **Abort** from error dialog = same as clicking **Cancel** button
- Both reset all nodes and stop execution
- Abort is just more convenient when error dialog is already open

---

### Test 23: Error Recovery - Multiple Errors ğŸ”„

**What it tests:** Error handling with multiple failing nodes

**Steps:**
1. Configure Settings with invalid API key
2. Create workflow with 3 agents:
   ```
   Agent 1 â†’ Agent 2 â†’ Agent 3 â†’ Result
   ```
3. All agents use the invalid API key
4. Click **Run** â–¶
5. When error dialog appears for Agent 1, click **Skip**
6. When error dialog appears for Agent 2, click **Skip**
7. When error dialog appears for Agent 3, click **Retry**
8. Before clicking Retry, fix API key in Settings
9. Click **Retry** in the error dialog

**Expected Results:**
- âœ… Error dialog appears three times (once per failing node)
- âœ… After first skip: Agent 1 stays red, Agent 2 executes
- âœ… After second skip: Agent 2 stays red, Agent 3 executes
- âœ… After fixing key and retry: Agent 3 succeeds
- âœ… Final state:
  - Agent 1: Red (skipped)
  - Agent 2: Red (skipped)
  - Agent 3: Green (completed after retry)
- âœ… Console shows all recovery actions

**Learning:**
- You can mix retry/skip strategies in one workflow
- Skipped nodes remain in error state for debugging
- Retried nodes reset and re-execute fresh

---

## Performance Benchmarks

Document your results:

| Test | Expected Time | Expected Cost | Pass/Fail |
|------|---------------|---------------|-----------|
| Test 3 (Streaming) | 2-5s | ~$0.0003 | â¬œ |
| Test 4 (Non-streaming) | 2-3s | ~$0.002 | â¬œ |
| Test 5 (Text upload) | <1s | Free | â¬œ |
| Test 6 (PDF upload) | 2-5s | Free | â¬œ |
| Test 7 (Docâ†’Agent) | 3-6s | ~$0.001 | â¬œ |
| Test 8 (Chunking) | <1s | Free | â¬œ |
| Test 9 (RAG workflow) | 5-10s | ~$0.003 | â¬œ |

---

## Known Issues & Limitations

### Expected Behavior (Not Bugs):
- **Execution is sequential**: Nodes run one at a time (not parallel)
- **Cost accumulates**: Each run costs money (use mock mode for free testing)
- **Long documents**: May exceed context window (100k+ characters)
- **Streaming updates all logs**: Previous logs visible while new ones stream
- **Pause waits for node completion**: Pause stops after current node finishes (not mid-node)
- **Error recovery interrupts flow**: Error dialogs appear immediately and pause execution until user responds

### Browser Compatibility:
- **Tested**: Chrome, Firefox, Safari (latest)
- **localStorage required**: Incognito mode may not persist API keys

---

## Troubleshooting Guide

### Issue: "Settings won't save"
- **Cause**: localStorage disabled or incognito mode
- **Fix**: Use regular browser window, check browser settings

### Issue: "Streaming doesn't show"
- **Cause**: Streaming checkbox unchecked
- **Fix**: Select node â†’ Properties â†’ Check "Streaming"

### Issue: "Nodes won't connect"
- **Cause**: Dragging from wrong handle
- **Fix**: Drag from **top** (source) to **bottom** (target) of nodes

### Issue: "Expensive costs"
- **Cause**: Using gpt-4o or claude-sonnet-4 with long prompts
- **Fix**: Switch to gpt-4o-mini or use mock mode

### Issue: "No response from agent"
- **Cause**: API key invalid, network error, or rate limit
- **Fix**: Check Settings â†’ Test key, wait if rate limited

### Issue: "Document preview is empty"
- **Cause**: PDF may have image-only text or special encoding
- **Fix**: Try different PDF or use text file

---

## Testing Checklist

Use this checklist to track your testing progress:

### Core Functionality
- [ ] Test 1: Settings & API Key Configuration
- [ ] Test 2: Basic Agent (Mock Mode)
- [ ] Test 3: Live Agent with Streaming
- [ ] Test 4: Non-Streaming Execution
- [ ] Test 5: Document Upload (Text)
- [ ] Test 6: Document Upload (PDF)
- [ ] Test 7: Document â†’ Agent Workflow
- [ ] Test 8: Document Chunking

### Advanced Features
- [ ] Test 9: Complex RAG Workflow
- [ ] Test 10: Multiple Providers
- [ ] Test 11: Streaming Auto-Scroll
- [ ] Test 12: Error - Invalid API Key
- [ ] Test 13: Error - Network Error
- [ ] Test 14: Visual Execution States
- [ ] Test 15: Multiple Documents â†’ Agent
- [ ] Test 16: Temperature Settings
- [ ] Test 17: Max Tokens Limit

### Execution Controls & Error Recovery
- [ ] Test 18: Execution Controls - Pause and Resume
- [ ] Test 19: Execution Controls - Cancel
- [ ] Test 20: Error Recovery - Retry
- [ ] Test 21: Error Recovery - Skip
- [ ] Test 22: Error Recovery - Abort
- [ ] Test 23: Error Recovery - Multiple Errors

### Edge Cases
- [ ] Large file upload (>5MB)
- [ ] Very long prompt (>1000 words)
- [ ] Multiple sequential runs
- [ ] Disconnecting/reconnecting nodes
- [ ] Deleting nodes mid-workflow
- [ ] Clearing canvas during execution
- [ ] Pausing execution immediately after starting
- [ ] Rapid pause/resume/cancel clicks
- [ ] Error recovery after network disconnection
- [ ] Multiple errors in parallel branches (if applicable)

---

## Reporting Issues

If you find bugs or unexpected behavior:

1. **Note the test number** where issue occurred
2. **Describe what happened** vs what was expected
3. **Check browser console** for errors (F12 â†’ Console tab)
4. **Note any error messages** shown in app console
5. **Document steps to reproduce**

---

## Next Steps After Testing

Once testing is complete:

1. âœ… **If all tests pass**: Ready to merge to main
2. âš ï¸ **If minor issues**: Document and continue
3. âŒ **If major issues**: Review implementation, fix critical bugs

**When ready to merge:**
```bash
git checkout main
git merge phase-1/foundation
git push origin main
```

---

**Happy Testing! ğŸš€**

For questions or issues, refer to:
- `PHASE1_COMPLETE.md` - Implementation summary
- `CLAUDE.md` - Architecture documentation
- `README.md` - Project overview
